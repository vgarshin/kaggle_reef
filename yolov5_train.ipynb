{"cells":[{"cell_type":"markdown","metadata":{"id":"808f9594"},"source":["# Yolov5 high resolution training"],"id":"808f9594"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqghZmp9_0Xl"},"outputs":[],"source":["VER = 'vclbyolo5_34'\n","WORK_DIR = '/content/drive/MyDrive/reef'"],"id":"iqghZmp9_0Xl"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a427573d"},"outputs":[],"source":["import os\n","import cv2\n","import json\n","import random\n","import torch\n","import numpy as np\n","import pandas as pd\n","from shutil import copyfile\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"a427573d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXYG2ocLAhJU"},"outputs":[],"source":["CONFIG = {\n","    'ver': VER,\n","    'bbone': 'yolov5s6.pt', # yolov5s6.pt yolov5m6.pt\n","    'width': 1280, \n","    'height': 720,\n","    'resize': 3840, # 3520 3008\n","    'batch_size': 2,\n","    'workers': 4,\n","    'bal_split': 'train_split_balanced_v1', #'train_split_balanced_v1', None\n","    'val_fold': 4,\n","    'val_video': 2,\n","    'empty_sh': .2,\n","    'mixup_prob': .5,\n","    'scale': .5, # default .5\n","    'shear': .2, # default 0\n","    'flipud': .5, # default .5\n","    'fliplr': .5, # default .5\n","    'epochs': 16,\n","    'seed': 2022\n","}\n","DATA_PATH = f'{WORK_DIR}/data'\n","if CONFIG[\"bal_split\"]:\n","    YDATA_PATH = f'{WORK_DIR}/data_vv5_bsvf{CONFIG[\"val_fold\"]}'\n","else:\n","    YDATA_PATH = f'{WORK_DIR}/data_vv5_{CONFIG[\"val_video\"]}'\n","MDLS_PATH = f'{WORK_DIR}/models_{VER}'\n","if not os.path.exists(MDLS_PATH):\n","    os.mkdir(MDLS_PATH)\n","with open(f'{MDLS_PATH}/config.json', 'w') as file:\n","    json.dump(CONFIG, file)\n","\n","def seed_all(seed=0):\n","    np.random.seed(seed)\n","    random_state = np.random.RandomState(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    return random_state    \n","    \n","random_state = seed_all(CONFIG['seed'])"],"id":"vXYG2ocLAhJU"},{"cell_type":"markdown","metadata":{"id":"C28AscTPkRev"},"source":["## Images and annotations"],"id":"C28AscTPkRev"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2e9e9a46"},"outputs":[],"source":["train = pd.read_csv(f'{DATA_PATH}/{CONFIG[\"bal_split\"]}.csv') if CONFIG[\"bal_split\"] else pd.read_csv(f'{DATA_PATH}/train.csv') \n","print(train.shape)\n","train['pos'] = train.annotations != '[]'\n","print(train.shape)\n","train.head()"],"id":"2e9e9a46"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8b71e00"},"outputs":[],"source":["fold = CONFIG[\"val_fold\"] if CONFIG[\"bal_split\"] else CONFIG[\"val_video\"]\n","if not os.path.exists(YDATA_PATH):\n","    os.mkdir(YDATA_PATH)\n","    for typ in ['images', 'labels']:\n","        path = f'{YDATA_PATH}/{typ}'\n","        if not os.path.exists(path):\n","            os.mkdir(path)\n","        for mode in ['train', 'val']:\n","            path = f'{YDATA_PATH}/{typ}/{mode}'\n","            if not os.path.exists(path):\n","                os.mkdir(path)\n","    annos = []\n","    for i, x in tqdm(train.iterrows(), total=len(train)):\n","        if CONFIG[\"bal_split\"]:\n","            if x.fold_id == fold:\n","                mode = 'val'\n","            else:\n","                mode = 'train'\n","                if not x.pos: continue\n","        else:\n","            if x.video_id == fold:\n","                mode = 'val'\n","            else:\n","                mode = 'train'\n","                if not x.pos: continue\n","        copyfile(\n","            f'{DATA_PATH}/train_images/video_{x.video_id}/{x.video_frame}.jpg',\n","            f'{YDATA_PATH}/images/{mode}/{x.image_id}.jpg'\n","        )\n","        if not x.pos:\n","            continue\n","        r = ''\n","        anno = eval(x.annotations)\n","        for an in anno:\n","            r += '0 {} {} {} {}\\n'.format(\n","                (an['x'] + an['width'] / 2) / CONFIG['width'],\n","                (an['y'] + an['height'] / 2) / CONFIG['height'],\n","                an['width'] / CONFIG['width'], \n","                an['height'] / CONFIG['height']\n","            )\n","        with open(f'{YDATA_PATH}/labels/{mode}/{x.image_id}.txt', 'w') as fp:\n","            fp.write(r)"],"id":"f8b71e00"},{"cell_type":"markdown","metadata":{"id":"imufeiEkkVe1"},"source":["## Train"],"id":"imufeiEkkVe1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f77ef231"},"outputs":[],"source":["hyps = '''\n","# YOLOv5 by Ultralytics, GPL-3.0 license\n","# Hyperparameters for COCO training from scratch\n","# python train.py --batch 40 --cfg yolov5m.yaml --weights '' --data coco.yaml --img 640 --epochs 300\n","# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n","\n","lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n","lrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\n","momentum: 0.937  # SGD momentum/Adam beta1\n","weight_decay: 0.0005  # optimizer weight decay 5e-4\n","warmup_epochs: 3.0  # warmup epochs (fractions ok)\n","warmup_momentum: 0.8  # warmup initial momentum\n","warmup_bias_lr: 0.1  # warmup initial bias lr\n","box: 0.05  # box loss gain\n","cls: 0.5  # cls loss gain\n","cls_pw: 1.0  # cls BCELoss positive_weight\n","obj: 1.0  # obj loss gain (scale with pixels)\n","obj_pw: 1.0  # obj BCELoss positive_weight\n","iou_t: 0.20  # IoU training threshold\n","anchor_t: 4.0  # anchor-multiple threshold\n","# anchors: 3  # anchors per output layer (0 to ignore)\n","fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n","hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n","hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n","hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n","degrees: 0.0  # image rotation (+/- deg)\n","translate: 0.1  # image translation (+/- fraction)\n","scale: <scale>  # image scale (+/- gain)\n","shear: <shear>  # image shear (+/- deg)\n","perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n","flipud: <flipud>  # image flip up-down (probability)\n","fliplr: <fliplr>  # image flip left-right (probability)\n","mosaic: 1.0  # image mosaic (probability)\n","mixup: 0.5  # image mixup (probability)\n","copy_paste: 0.0  # segment copy-paste (probability)\n","'''\n","hyps = hyps.replace('<scale>', str(CONFIG['scale']))\n","hyps = hyps.replace('<shear>', str(CONFIG['shear']))\n","hyps = hyps.replace('<flipud>', str(CONFIG['flipud']))\n","hyps = hyps.replace('<fliplr>', str(CONFIG['fliplr']))\n","print(hyps)"],"id":"f77ef231"},{"cell_type":"code","execution_count":null,"metadata":{"id":"97318f43"},"outputs":[],"source":["data = '''\n","# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n","path: <path> #../yolo_data/fold1/  # dataset root dir\n","train: images/train  # train images (relative to 'path') 128 images\n","val: images/val  # val images (relative to 'path') 128 images\n","test:  # test images (optional)\n","\n","# Classes\n","nc: 1  # number of classes\n","names: ['star']  # class names\n","\n","# Download script/URL (optional)\n","# download: https://ultralytics.com/assets/coco128.zip\n","'''\n","data = data.replace('<path>', YDATA_PATH)\n","print(data)"],"id":"97318f43"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0ee379a"},"outputs":[],"source":["!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","%pip install -qr requirements.txt"],"id":"a0ee379a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7d49eb7"},"outputs":[],"source":["with open('./data/reef_f1_naive.yaml', 'w') as fp:\n","    fp.write(data)\n","with open('./data/hyps/hyp.heavy.2.yaml', 'w') as fp:\n","    fp.write(hyps)"],"id":"b7d49eb7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3070ec21"},"outputs":[],"source":["!ls data/"],"id":"3070ec21"},{"cell_type":"code","execution_count":null,"metadata":{"id":"JyWy11fKabsj"},"outputs":[],"source":["!ls -la -r runs/train/"],"id":"JyWy11fKabsj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQofM1gjlPfY"},"outputs":[],"source":["model_name = f'model_{CONFIG[\"ver\"]}'\n","resize = CONFIG['resize']\n","batch_size = CONFIG['batch_size']\n","epochs = CONFIG['epochs']\n","bbone = CONFIG['bbone']"],"id":"TQofM1gjlPfY"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Burzceg2mkdu"},"outputs":[],"source":["!python train.py \\\n","    --img $resize \\\n","    --batch $batch_size \\\n","    --epochs $epochs \\\n","    --data reef_f1_naive.yaml \\\n","    --weights $bbone \\\n","    --name $model_name \\\n","    --hyp data/hyps/hyp.heavy.2.yaml"],"id":"Burzceg2mkdu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rA72fXVJ9D-m"},"outputs":[],"source":["!cp -r runs/train/$model_name/* $MDLS_PATH/"],"id":"rA72fXVJ9D-m"},{"cell_type":"markdown","metadata":{"id":"qFQDLZpFkZVE"},"source":["## Inference"],"id":"qFQDLZpFkZVE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVemFC8S9rsK"},"outputs":[],"source":["model = torch.hub.load(\n","    '.', \n","    'custom', \n","    path=f'{MDLS_PATH}/weights/best.pt',\n","    source='local',\n","    force_reload=True\n",")\n","model.conf = 0.01"],"id":"EVemFC8S9rsK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtAAsIT9dmWg"},"outputs":[],"source":["def draw_boxes(img, bboxes, scores=None):\n","    color = (0, 255, 0) if scores else (0, 0, 255)\n","    for i in range(len(bboxes)):\n","        box = bboxes[i]\n","        text = '{} {:.1f}%'.format('pred', scores[i] * 100) if scores else 'gt'\n","        x0 = int(box[0])\n","        y0 = int(box[1])\n","        x1 = int(box[2])\n","        y1 = int(box[3])\n","        cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n","        cv2.putText(\n","            img, \n","            text, \n","            (x0, y0 - 3), \n","            cv2.FONT_HERSHEY_PLAIN, \n","            1.4, \n","            color, \n","            thickness=2\n","        )\n","    return img"],"id":"GtAAsIT9dmWg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByLeUb35rK8r"},"outputs":[],"source":["%matplotlib inline\n","\n","count = 0\n","max_count = 8\n","\n","for i, x in train.iterrows():\n","    #if x.video_id == fold:\n","    if x.fold_id == fold:\n","        if not x.pos:\n","            continue\n","        count += 1\n","        img_path = f'{YDATA_PATH}/images/val/{x.image_id}.jpg'\n","        img = cv2.imread(img_path)\n","        print(count, img_path)\n","        anno = eval(x.annotations)\n","        gt_bboxes = []\n","        for an in anno:\n","            gt_bboxes.append([\n","                an['x'],\n","                an['y'],\n","                an['x'] + an['width'], \n","                an['y'] + an['height']               \n","            ])\n","        res = model(img, size=CONFIG['resize'], augment=True)\n","        pred_bboxes = []\n","        pred_scores = []\n","        if res.pandas().xyxy[0].shape[0] == 0:\n","            pass\n","        else:\n","            for idx, row in res.pandas().xyxy[0].iterrows():\n","                pred_bboxes.append([\n","                    row.xmin, \n","                    row.ymin, \n","                    row.xmax, \n","                    row.ymax                    \n","                ])\n","                pred_scores.append(row.confidence)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = draw_boxes(img, gt_bboxes, scores=None)\n","        img = draw_boxes(img, pred_bboxes, scores=pred_scores)\n","        plt.figure(figsize=(20, 10))\n","        plt.imshow(img)\n","        plt.show()\n","        if count >= max_count:\n","            break"],"id":"ByLeUb35rK8r"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5jPHolsm8NI"},"outputs":[],"source":[""],"id":"e5jPHolsm8NI"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"yolov5_train.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":16143.063915,"end_time":"2022-01-13T20:20:15.069519","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-01-13T15:51:12.005604","version":"2.3.3"}},"nbformat":4,"nbformat_minor":5}