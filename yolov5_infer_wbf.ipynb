{"cells":[{"cell_type":"markdown","metadata":{"id":"808f9594"},"source":["# Yolov5 inference with WBF"],"id":"808f9594"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a427573d"},"outputs":[],"source":["import os\n","import cv2\n","import json\n","import random\n","import torch\n","import numpy as np\n","import pandas as pd\n","from shutil import copyfile\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"a427573d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqghZmp9_0Xl"},"outputs":[],"source":["VERS = [\n","    'vclbyolo5_3',\n","    'vclbyolo5_4',\n","    'vclbyolo5_5'\n","]\n","WORK_DIR = '/content/drive/MyDrive/reef'\n","MDLS_PATHS = []\n","CONFIGS = []\n","for ver in VERS:\n","    mdl_path = f'{WORK_DIR}/models_{ver}'\n","    MDLS_PATHS.append(mdl_path)\n","    with open(f'{mdl_path}/config.json', 'r') as file:\n","        CONFIGS.append(json.load(file))\n","print('configs loaded:', CONFIGS)\n","DATA_PATH = f'{WORK_DIR}/data'\n","VAL_FOLD = CONFIGS[2][\"val_video\"]\n","YDATA_PATH = f'{WORK_DIR}/data_vv5_{VAL_FOLD}'\n","\n","WBF_IOU_TH = .5, \n","WBF_SKIP_BOX_TH = .0001"],"id":"iqghZmp9_0Xl"},{"cell_type":"markdown","metadata":{"id":"C28AscTPkRev"},"source":["## Install packages"],"id":"C28AscTPkRev"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0ee379a"},"outputs":[],"source":["!pip install ensemble-boxes\n","!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","%pip install -qr requirements.txt"],"id":"a0ee379a"},{"cell_type":"markdown","metadata":{"id":"qFQDLZpFkZVE"},"source":["## Inference"],"id":"qFQDLZpFkZVE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVemFC8S9rsK"},"outputs":[],"source":["MODELS = []\n","for mdl_path in MDLS_PATHS:\n","    model = torch.hub.load(\n","        '.', \n","        'custom', \n","        path=f'{mdl_path}/weights/best.pt',\n","        source='local',\n","        force_reload=True\n","    )\n","    model.conf = 0.01\n","    MODELS.append(model)\n","    print('loaded:', mdl_path)"],"id":"EVemFC8S9rsK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtAAsIT9dmWg"},"outputs":[],"source":["def draw_boxes(img, bboxes, scores=[]):\n","    color = (0, 255, 0) if len(scores) > 0 else (0, 0, 255)\n","    for i in range(len(bboxes)):\n","        box = bboxes[i]\n","        text = '{} {:.1f}%'.format('pred', scores[i] * 100) if len(scores) > 0 else 'gt'\n","        x0 = int(box[0])\n","        y0 = int(box[1])\n","        x1 = int(box[2])\n","        y1 = int(box[3])\n","        cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n","        cv2.putText(\n","            img, \n","            text, \n","            (x0, y0 - 3), \n","            cv2.FONT_HERSHEY_PLAIN, \n","            1.4, \n","            color, \n","            thickness=2\n","        )\n","    return img"],"id":"GtAAsIT9dmWg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2e9e9a46"},"outputs":[],"source":["train = pd.read_csv(f'{DATA_PATH}/train.csv')\n","train['pos'] = train.annotations != '[]'"],"id":"2e9e9a46"},{"cell_type":"code","execution_count":null,"metadata":{"id":"758Rbugq8Icc"},"outputs":[],"source":["from ensemble_boxes import *"],"id":"758Rbugq8Icc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9v2NmQmi8QeR"},"outputs":[],"source":["def run_wbf(bboxes, scores, \n","            img_size, iou_thr=0.55, \n","            skip_box_thr=0.7, weights=None):\n","    #print('img shape for WBF:', img_size, img_size[1], img_size[0])\n","    boxes = [[[x[0] / img_size[1],\n","               x[1] / img_size[0],\n","               x[2] / img_size[1],\n","               x[3] / img_size[0]] for x in bbox] for bbox in bboxes]\n","    #print('boxes for WBF:', boxes)\n","    labels = [np.ones(len(s)) for s in scores]\n","    #print('scores for WBF:', scores)\n","    #print('labels for WBF:', labels)\n","    boxes, scores, labels = weighted_boxes_fusion(\n","        boxes, scores, labels, \n","        weights=weights, iou_thr=iou_thr, \n","        skip_box_thr=skip_box_thr\n","    )\n","    boxes = [[int(x[0] * img_size[1]),\n","              int(x[1] * img_size[0]),\n","              int(x[2] * img_size[1]),\n","              int(x[3] * img_size[0])] for x in boxes]\n","    return boxes, scores, labels\n","\n","def predict(model, img, size, aug=True):\n","    results = model(img, size=size, augment=aug)\n","    preds = results.pandas().xyxy[0]\n","    bboxes = preds[['xmin','ymin','xmax','ymax']].values\n","    if len(bboxes):\n","        bboxes = bboxes.astype(int)\n","        confs = preds.confidence.values\n","        return bboxes, confs\n","    else:\n","        return [], []"],"id":"9v2NmQmi8QeR"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ByLeUb35rK8r"},"outputs":[],"source":["%matplotlib inline\n","\n","count = 0\n","max_count = 32\n","\n","for i, x in train.iterrows():\n","    if x.video_id == VAL_FOLD:\n","        if not x.pos:\n","            continue\n","        count += 1\n","        img_path = f'{YDATA_PATH}/images/val/{x.image_id}.jpg'\n","        img = cv2.imread(img_path)\n","        print()\n","        print(count, '||', img_path, '||', img.shape)\n","        anno = eval(x.annotations)\n","        gt_bboxes = []\n","        for an in anno:\n","            gt_bboxes.append([\n","                an['x'],\n","                an['y'],\n","                an['x'] + an['width'], \n","                an['y'] + an['height']               \n","            ])\n","        print('ground truth boxes:', gt_bboxes)\n","        pred_bboxes = []\n","        pred_scores = []\n","        for model, config in zip(MODELS, CONFIGS):\n","            bboxes, confs =  predict(model, img, size=config['resize'], aug=True)\n","            if len(bboxes) > 0:\n","                pred_bboxes.append(bboxes.tolist())\n","                pred_scores.append(confs.tolist())\n","        print('pred boxes BEFORE WBF:', pred_bboxes)\n","        print('pred scores BEFORE WBF:', pred_scores)\n","        pred_bboxes, pred_scores, labels = run_wbf(\n","            pred_bboxes, pred_scores, \n","            img_size=img.shape, iou_thr=WBF_IOU_TH, \n","            skip_box_thr=WBF_SKIP_BOX_TH, weights=None\n","        )\n","        print('pred boxes AFTER WBF:', pred_bboxes)\n","        print('pred scores AFTER WBF:', pred_scores)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = draw_boxes(img, gt_bboxes, scores=[])\n","        img = draw_boxes(img, pred_bboxes, scores=pred_scores)\n","        plt.figure(figsize=(20, 10))\n","        plt.imshow(img)\n","        plt.show()\n","        if count >= max_count:\n","            break"],"id":"ByLeUb35rK8r"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wv4IhYyVJvuA"},"outputs":[],"source":[""],"id":"Wv4IhYyVJvuA"}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"yolov5_infer_wbf.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":16143.063915,"end_time":"2022-01-13T20:20:15.069519","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-01-13T15:51:12.005604","version":"2.3.3"}},"nbformat":4,"nbformat_minor":5}